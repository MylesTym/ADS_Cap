{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47e9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle null values in text column\n",
    "df['consumer_complaint_narrative'] = df['consumer_complaint_narrative'].fillna('')\n",
    "domain_stop_words = list(ENGLISH_STOP_WORDS) + [\n",
    "    'credit', 'report', 'account', 'information',\n",
    "    'consumer', 'reporting', 'told', 'called',\n",
    "    'did', 'received', 'company'\n",
    "]\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=domain_stop_words,\n",
    "    token_pattern=r'(?u)\\b(?!x{2,}\\b)(?!X{2,}\\b)[A-Za-z]\\w+',\n",
    "    min_df= 5,\n",
    "    max_df=1.0,\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=1000)\n",
    "x = vectorizer.fit_transform(df['consumer_complaint_narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd335dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5 ## test diffrent variable amounts\n",
    "kmeans = KMeans(n_clusters=k, random_state=25)\n",
    "labels = kmeans.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 top terms:\n",
      "credit, report, information, xxxx, reporting, identity, accounts, theft, account, inquiries, \n",
      "Cluster 1 top terms:\n",
      "consumer, xxxx, information, 15, reporting, report, consent, code, agency, reports, \n",
      "Cluster 2 top terms:\n",
      "section, usc, 15, 1681, consumer, states, xxxx, reporting, agency, furnish, \n",
      "Cluster 3 top terms:\n",
      "xxxx, xxxxxxxx, account, credit, report, information, reporting, accounts, balance, date, \n",
      "Cluster 4 top terms:\n",
      "debt, xxxx, collection, company, credit, validation, account, proof, alleged, report, \n",
      "Cluster 5 top terms:\n",
      "accounts, credit, report, inaccurate, duty, litigation, fraudulent, accordingly, deny, inaccuracies, \n",
      "Cluster 6 top terms:\n",
      "xxxx, xxxxxxxx, credit, report, items, information, consumer, balance, account, reporting, \n",
      "Cluster 7 top terms:\n",
      "xxxx, account, bank, card, payment, loan, xxxxxxxx, told, credit, called, \n",
      "Cluster 8 top terms:\n",
      "letters, xxxx, complaint, filing, party, involved, im, uploaded, falsely, misleading, \n",
      "Cluster 9 top terms:\n",
      "late, payment, payments, xxxx, error, credit, account, reporting, report, consumer, "
     ]
    }
   ],
   "source": [
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Add cluster evaluation metrics\n",
    "sil_score = silhouette_score(x, labels)\n",
    "print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "print(f\"Cluster sizes: {np.bincount(labels)}\")\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"\\nCluster {i} top terms:\")\n",
    "    for j in order_centroids[i, :10]:  # Top 10 terms\n",
    "        print(terms[j], end=\", \")\n",
    "    print(f\"\\nSize: {np.bincount(labels)[i]} complaints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method for optimal K selection\n",
    "inertias = []\n",
    "k_range = range(2, 8)\n",
    "\n",
    "for k_test in k_range:\n",
    "    kmeans_test = KMeans(n_clusters=k_test, random_state=25)\n",
    "    kmeans_test.fit(x)\n",
    "    inertias.append(kmeans_test.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, inertias, 'bo-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b207505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced cluster interpretation\n",
    "df['cluster'] = labels\n",
    "\n",
    "print(\"=== CLUSTER INTERPRETATION ===\")\n",
    "for i in range(k):\n",
    "    cluster_data = df[df['cluster'] == i]\n",
    "    print(f\"\\nCluster {i} - Size: {len(cluster_data)} ({len(cluster_data)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Sample complaints\n",
    "    samples = cluster_data['consumer_complaint_narrative'].dropna().head(2)\n",
    "    for idx, complaint in enumerate(samples, 1):\n",
    "        if complaint.strip():\n",
    "            print(f\"  Sample {idx}: {complaint[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ab6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster visualization\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Cluster size distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "cluster_sizes = np.bincount(labels)\n",
    "plt.bar(range(k), cluster_sizes)\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Complaints')\n",
    "plt.title('Cluster Size Distribution')\n",
    "plt.xticks(range(k))\n",
    "\n",
    "# PCA visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "pca = PCA(n_components=2, random_state=25)\n",
    "x_pca = pca.fit_transform(x.toarray())\n",
    "scatter = plt.scatter(x_pca[:, 0], x_pca[:, 1], c=labels, cmap='viridis', alpha=0.6)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Clusters in PCA Space')\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf3789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cluster results\n",
    "df_clusters = df[['consumer_complaint_narrative', 'cluster']].copy()\n",
    "df_clusters.to_csv('../data/cluster_results.csv', index=False)\n",
    "\n",
    "print(f\"Cluster results exported to ../data/cluster_results.csv\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Silhouette score: {sil_score:.3f}\")\n",
    "print(f\"Clusters: {k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
